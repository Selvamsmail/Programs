{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pytz\n",
    "import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_setup():# Assigning a Headless Firefox Driver\n",
    "  options = webdriver.FirefoxOptions()\n",
    "  options.binary_location = 'C:/Program Files/Mozilla Firefox/firefox.exe'  # Path to Chrome executable\n",
    "  options.add_argument('E:/Programs/geckodriver.exe')\n",
    "  # options.add_argument('--headless')\n",
    "  options.add_argument('--no-sandbox')\n",
    "  options.add_argument('--disable-dev-shm-usage')\n",
    "  driver = webdriver.Firefox(options=options)\n",
    "  return driver\n",
    "\n",
    "def save_data_to_disk(data, filename):\n",
    "    if os.path.isfile(filename):\n",
    "        existing_df = pd.read_parquet(filename)\n",
    "        data = pd.concat([existing_df, data], ignore_index=True)\n",
    "        os.remove(filename)\n",
    "        data.to_parquet(filename, index=False)\n",
    "    else:\n",
    "        data.to_parquet(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of firefox cannot be detected. Trying with latest driver version\n"
     ]
    }
   ],
   "source": [
    "driver = driver_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(f\"https://www.linkedin.com/authwall?trk=qf&original_referer=&sessionRedirect=https%3A%2F%2Fwww.linkedin.com%2F\")\n",
    "Sign_in_button = driver.find_element(By.XPATH, \"/html/body/div/main/div/form/p/button\").click()\n",
    "time.sleep(5)\n",
    "email_phone = driver.find_element(By.XPATH, '//*[@id=\"session_key\"]')\n",
    "password = driver.find_element(By.XPATH, '//*[@id=\"session_password\"]')\n",
    "email_phone.send_keys(\"pannersmail@gmail.com\")\n",
    "# email_phone.send_keys(\"r.panneerselvam@firebird.net.in\")\n",
    "password.send_keys(\"Mk90473@yahoo.com\")\n",
    "\n",
    "# email_phone.send_keys(\"renjithcm.renju@gmail.com\")\n",
    "# password.send_keys(\"Renjith#@1\")\n",
    "submit_button = driver.find_element(By.XPATH, \"/html/body/div/main/div/div/form[1]/div[2]/button\")\n",
    "submit_button.click()\n",
    "\n",
    "wait = WebDriverWait(driver, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"13760002\"%2C\"15100441\"%2C\"15101508\"%2C\"15102074\"%2C\"15104017\"%2C\"15200530\"%2C\"16921\"%2C\"265652\"%2C\"2850888\"%2C\"2878912\"%2C\"3083\"%2C\"3157\"%2C\"3322\"%2C\"3352\"%2C\"3890\"%2C\"4521\"%2C\"5523\"%2C\"8345\"%2C\"8385397\"]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'[\"13760002\"%2C\"15100441\"%2C\"15101508\"%2C\"15102074\"%2C\"15104017\"%2C\"15200530\"%2C\"16921\"%2C\"265652\"%2C\"2850888\"%2C\"2878912\"%2C\"3083\"%2C\"3157\"%2C\"3322\"%2C\"3352\"%2C\"3890\"%2C\"4521\"%2C\"5523\"%2C\"8345\"%2C\"8385397\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg = 1\n",
    "# links= []\n",
    "# while True:    \n",
    "#     # url = f'https://www.linkedin.com/search/results/people/?geoUrn=%5B%22102713980%22%5D&keywords=%22MBA%22&origin=GLOBAL_SEARCH_HEADER&page=1&schoolFilter=%5B%223890%22%2C%2215100441%22%2C%228385397%22%2C%2215100308%22%2C%223083%22%2C%225523%22%2C%222878912%22%2C%2216921%22%2C%228398%22%2C%222850888%22%2C%223195%22%2C%223352%22%2C%223157%22%2C%228345%22%2C%2215102074%22%2C%225290%22%2C%225954%22%2C%224476%22%2C%224521%22%2C%2213760002%22%2C%22265652%22%2C%2215200530%22%2C%223322%22%2C%2215101508%22%2C%2215104017%22%2C%2215101634%22%5D&sid=hR9'\n",
    "#     # url = f'https://www.linkedin.com/search/results/people/?geoUrn=%5B%22102713980%22%5D&keywords=%22mba%22&origin=GLOBAL_SEARCH_HEADER&page='+str(pg)+f'&schoolFilter=%5B%2213760002%22%2C%2215100308%22%2C%2215100441%22%2C%2215101508%22%2C%2215102074%22%2C%2215104017%22%2C%2215200530%22%2C%2216921%22%2C%22265652%22%2C%222850888%22%2C%222878912%22%2C%223083%22%2C%223157%22%2C%223322%22%2C%223352%22%2C%223890%22%2C%224476%22%2C%224521%22%2C%225523%22%2C%228345%22%2C%228385397%22%2C%228398%22%5D&sid=%3BH3'\n",
    "#     # url = f'https://www.linkedin.com/search/results/people/?geoUrn=%5B%22102713980%22%5D&keywords=%22mba%22&origin=GLOBAL_SEARCH_HEADER&page='+str(pg)+f'&schoolFilter=%5B%2213760002%22%2C%2215100308%22%2C%2215100441%22%2C%2215101508%22%2C%2215102074%22%2C%2215104017%22%2C%2215200530%22%2C%2216921%22%2C%22265652%22%2C%222850888%22%2C%222878912%22%2C%223083%22%2C%223157%22%2C%223322%22%2C%223352%22%2C%223890%22%2C%224476%22%2C%224521%22%2C%225523%22%2C%228345%22%2C%228385397%22%2C%228398%22%5D'\n",
    "#     url = f'https://www.linkedin.com/search/results/people/?geoUrn=%5B%22102713980%22%5D&keywords=%22mba%22&origin=GLOBAL_SEARCH_HEADER&page='+str(pg)+f'&schoolFilter=[\"15101508\"%2C\"2850888\"%2C\"2878912\"%2C\"3083\"%2C\"3157\"%2C\"3322\"%2C\"3352\"%2C\"3890\"%2C\"4521\"%2C\"5523\"%2C\"8345\"%2C\"8385397\"]'\n",
    "#     driver.get(url)\n",
    "#     #------------------------------------------------------------------------------------------------------\n",
    "#     time.sleep(4)\n",
    "#     # break \n",
    "#     #------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "#     li_elements = driver.find_elements(By.CLASS_NAME, \"reusable-search__result-container\")\n",
    "\n",
    "#     # Iterate over the li elements and extract the link\n",
    "#     for li in li_elements:\n",
    "#         link_element = li.find_element(By.TAG_NAME, \"a\")\n",
    "#         link = link_element.get_attribute(\"href\")\n",
    "#         links.append(link)\n",
    "        \n",
    "#         if link != '':\n",
    "#             tempdf = pd.DataFrame({'Link': [link]})\n",
    "#             tempfilename = 'links.parquet'\n",
    "\n",
    "#             save_data_to_disk(tempdf, tempfilename)\n",
    "#             tempdf = pd.DataFrame()\n",
    "#     pg += 1\n",
    "#     print(f'\\rProgress: {len(links)}', end='')\n",
    "#     # if len(links) > 500:\n",
    "#     #     break \n",
    "#     if pg > 100:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/in/prasadchandran?min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/in/tamilmani-selvan-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/in/shrutipy?miniProfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/in/siddharth-jain-71a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/in/swapnil-more-8b2a3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>https://www.linkedin.com/in/rahulmgupta?miniPr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>https://www.linkedin.com/in/kalyankumarbh?mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>https://www.linkedin.com/in/sharad-somani?mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8990</th>\n",
       "      <td>https://www.linkedin.com/in/shravan-sharma-616...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8991</th>\n",
       "      <td>https://www.linkedin.com/in/pooja-bharwani-b13...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8992 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Link\n",
       "0     https://www.linkedin.com/in/prasadchandran?min...\n",
       "1     https://www.linkedin.com/in/tamilmani-selvan-1...\n",
       "2     https://www.linkedin.com/in/shrutipy?miniProfi...\n",
       "3     https://www.linkedin.com/in/siddharth-jain-71a...\n",
       "4     https://www.linkedin.com/in/swapnil-more-8b2a3...\n",
       "...                                                 ...\n",
       "8987  https://www.linkedin.com/in/rahulmgupta?miniPr...\n",
       "8988  https://www.linkedin.com/in/kalyankumarbh?mini...\n",
       "8989  https://www.linkedin.com/in/sharad-somani?mini...\n",
       "8990  https://www.linkedin.com/in/shravan-sharma-616...\n",
       "8991  https://www.linkedin.com/in/pooja-bharwani-b13...\n",
       "\n",
       "[8992 rows x 1 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linksdf = pd.read_parquet('links.parquet')\n",
    "linksdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "linksdf.drop_duplicates(inplace=True)\n",
    "linksdf.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "linksdf.to_parquet('Links.parquet',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8992, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linksdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('linkedin_compleation_new.txt', 'r') as file:\n",
    "    current_ind = int(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8967"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(int(linksdf.shape[0]) - int(current_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.linkedin.com/in/amit-ranjan-gupta?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAebO_0Bdq7ax84PL0iEjzFA8Wcscn4AYa0'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linksdf['Link'][current_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: 25, current ind: 8992"
     ]
    }
   ],
   "source": [
    "runtill = 0\n",
    "\n",
    "# pbar = tqdm(total=83, desc='Scrapeing', unit='profile')\n",
    "\n",
    "for linkind in range(current_ind, len(linksdf)):\n",
    "    # pbar.update(1)\n",
    "\n",
    "    companies = []\n",
    "    \n",
    "    driver.get(linksdf['Link'][linkind])\n",
    "    time.sleep((random.randint(7, 20)))\n",
    "    main = {} \n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    data = {}\n",
    "    try:\n",
    "        name = h1_element = driver.find_element(By.CLASS_NAME, \"text-heading-xlarge\").text\n",
    "    except:\n",
    "        # continue\n",
    "        None\n",
    "    try:\n",
    "        # driver.find_element(By.CSS_SELECTOR, '[id^=\"ember\"] > div.ph5 > div.mt2.relative > div.pv-text-details__left-panel.mt2 > span.text-body-small.inline.t-black--light.break-words').text\n",
    "        location = driver.find_element(By.CSS_SELECTOR, 'span.text-body-small.inline.t-black--light.break-words').text\n",
    "    except:\n",
    "        location = None\n",
    "    try:\n",
    "        data['name']=name\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        data['location']=location\n",
    "    except:\n",
    "        None\n",
    "    main.update(data)\n",
    "    #-----------------------------------------follow-------------------------------------------------------------\n",
    "    # try:\n",
    "    #     followbutton = driver.find_element(By.CLASS_NAME, \"pvs-profile-actions__action\")\n",
    "    #     followbutton.click()\n",
    "    # except:\n",
    "    #     None    \n",
    "    #-----------------------------------get relevant cards-------------------------------------------------------------------\n",
    "    pvs_header_elements = driver.find_elements(By.CSS_SELECTOR, '.artdeco-card')\n",
    "\n",
    "    pvs_header_ind = {\n",
    "        'exp': None,\n",
    "        'edu': None,\n",
    "        'skil': None\n",
    "    }\n",
    "\n",
    "    for eleind in range(len(pvs_header_elements)):\n",
    "        try:\n",
    "            t = pvs_header_elements[eleind].find_element(By.CLASS_NAME, \"pvs-header__title-container\").text.lower()\n",
    "            if ('experience' in t):\n",
    "                pvs_header_ind['exp'] = eleind\n",
    "            elif ('education' in t):\n",
    "                pvs_header_ind['edu'] = eleind\n",
    "            elif ('skills' in t):\n",
    "                pvs_header_ind['skil'] = eleind\n",
    "        except:\n",
    "            None\n",
    "    exp = pvs_header_ind['exp']\n",
    "    edu = pvs_header_ind['edu']\n",
    "    skil = pvs_header_ind['skil']\n",
    "\n",
    "    #---------------------------------------Experience Card----------------------------------------------------------------\n",
    "    if exp != None:\n",
    "        data={}\n",
    "\n",
    "        all_ele = pvs_header_elements[exp].find_elements(By.XPATH, \".//*\")\n",
    "        footer = []\n",
    "        for ele in all_ele:\n",
    "            class_name = ele.get_attribute(\"class\")\n",
    "            footer.append(class_name)\n",
    "            \n",
    "        flag = 'n'\n",
    "        for i in footer:\n",
    "            if i != None:\n",
    "                if 'pvs-list__footer-wrapper' in i:\n",
    "                    flag = 'y'\n",
    "        \n",
    "        if flag == 'y':\n",
    "            explink = pvs_header_elements[exp].find_element(By.CLASS_NAME, \"pvs-list__footer-wrapper\").find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "            driver.get(explink)\n",
    "            time.sleep(10)\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"button[aria-label='Back to the main profile page']\")))\n",
    "            # pvs_list_outer_container = pvs_header_elements[exp].find_element(By.CSS_SELECTOR, \"div.pvs-list__outer-container\")\n",
    "            \n",
    "            li_elements = driver.find_elements(By.CSS_SELECTOR, \"li.artdeco-list__item\")\n",
    "            \n",
    "            for li_ind in range(len(li_elements)):     \n",
    "                add_du_pvs = 0\n",
    "                \n",
    "                node_elements = li_elements[li_ind].find_elements(By.TAG_NAME, \"span\")\n",
    "                node = []\n",
    "                for element in node_elements:\n",
    "                    class_name = element.get_attribute(\"class\")\n",
    "                    node.append(class_name)\n",
    "                    \n",
    "                flag = 'n'\n",
    "                for i in node:\n",
    "                    if i != None:\n",
    "                        if 'pvs-entity__path-node' in i:\n",
    "                            flag = 'y'\n",
    "                \n",
    "                if flag == 'y':\n",
    "                    subliele = li_elements[li_ind].find_elements(By.CLASS_NAME, \"pvs-list__paged-list-item\")\n",
    "                    \n",
    "                    try:\n",
    "                        company_link = li_elements[li_ind].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                        companies.append(company_link)\n",
    "                    except:\n",
    "                        company_link = None\n",
    "                        companies.append(company_link)\n",
    "                        \n",
    "                    for sub_ind in range(len(subliele)):\n",
    "                        \n",
    "                        try:\n",
    "                            title = subliele[sub_ind].find_element(By.CLASS_NAME, \"t-bold\").text\n",
    "                        except:\n",
    "                            title = None\n",
    "                        try:\n",
    "                            org =  li_elements[li_ind].find_element(By.CLASS_NAME, \"t-bold\").text \n",
    "                        except:\n",
    "                            org = None\n",
    "                        try:\n",
    "                            duration = subliele[sub_ind].find_element(By.CLASS_NAME, \"t-14.t-normal.t-black--light\").text\n",
    "                        except:\n",
    "                            duration = None\n",
    "                        try:\n",
    "                            location = subliele[-1].find_elements(By.CLASS_NAME, \"t-14.t-normal.t-black--light\")\n",
    "                        except:\n",
    "                            location = None\n",
    "                        try:\n",
    "                            data['title_'+str(li_ind)+'_sub_'+str(sub_ind)] = title.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['title_'+str(li_ind)+'_sub_'+str(sub_ind)] = None\n",
    "                        try:\n",
    "                            data['org_'+str(li_ind)+'_sub_'+str(sub_ind)] = org.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['org_'+str(li_ind)+'_sub_'+str(sub_ind)] = None\n",
    "                        try:\n",
    "                            data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_duration'] = duration.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_duration'] = None\n",
    "                        try:\n",
    "                            data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_location'] = location[1].text.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_location'] = None\n",
    "                        \n",
    "                else:         \n",
    "                    \n",
    "                    try:\n",
    "                        company_link = li_elements[li_ind].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                        companies.append(company_link)\n",
    "                    except:\n",
    "                        company_link = None\n",
    "                        companies.append(company_link)\n",
    "                        \n",
    "                    try:\n",
    "                        title = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-bold\").text \n",
    "                    except:\n",
    "                        title = None\n",
    "                    try:\n",
    "                        org = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal\").text\n",
    "                    except:\n",
    "                        org = None\n",
    "                    try:\n",
    "                        duration = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal.t-black--light\").text\n",
    "                    except:\n",
    "                        duration = None\n",
    "                    try:\n",
    "                        location = li_elements[li_ind].find_elements(By.CLASS_NAME, \"t-14.t-normal.t-black--light\")\n",
    "                    except:\n",
    "                        location = None\n",
    "                    try:\n",
    "                        data['title_'+str(li_ind)] = title.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['title_'+str(li_ind)] = None\n",
    "                    try:\n",
    "                        data['org_'+str(li_ind)] = org.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['org_'+str(li_ind)] = None\n",
    "                    try:\n",
    "                        data['job_'+str(li_ind)+'_duration'] = duration.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['job_'+str(li_ind)+'_duration'] = None\n",
    "                    try:\n",
    "                        data['job_'+str(li_ind)+'_location'] = location[1].text.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['job_'+str(li_ind)+'_location'] = None\n",
    "\n",
    "            driver.back()\n",
    "            time.sleep((random.randint(7, 20)))\n",
    "        else:\n",
    "            try:\n",
    "                pvs_list_outer_container = pvs_header_elements[exp].find_element(By.CSS_SELECTOR, \"div.pvs-list__outer-container\")\n",
    "                ul = pvs_list_outer_container.find_element(By.CLASS_NAME, 'pvs-list')\n",
    "                li_elements = ul.find_elements(By.XPATH, './li')\n",
    "                li_elements = [li for li in li_elements if not li.text.startswith(\"Skills\")]\n",
    "                \n",
    "                for li_ind in range(len(li_elements)):     \n",
    "                    add_du_pvs = 0\n",
    "                    \n",
    "                    node_elements = li_elements[li_ind].find_elements(By.TAG_NAME, \"span\")\n",
    "                    node = []\n",
    "                    for element in node_elements:\n",
    "                        class_name = element.get_attribute(\"class\")\n",
    "                        node.append(class_name)\n",
    "                        \n",
    "                    flag = 'n'\n",
    "                    for i in node:\n",
    "                        if i != None:\n",
    "                            if 'pvs-entity__path-node' in i:\n",
    "                                flag = 'y'\n",
    "                    \n",
    "                    if flag == 'y':\n",
    "                        subliele = li_elements[li_ind].find_elements(By.CLASS_NAME, \"pvs-list__paged-list-item\")\n",
    "                        \n",
    "                        try:\n",
    "                            company_link = li_elements[li_ind].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                            companies.append(company_link)\n",
    "                        except:\n",
    "                            company_link = None\n",
    "                            companies.append(company_link)\n",
    "                            \n",
    "                        for sub_ind in range(len(subliele)):\n",
    "                            \n",
    "                            try:\n",
    "                                title = subliele[sub_ind].find_element(By.CLASS_NAME, \"t-bold\").text\n",
    "                            except:\n",
    "                                title = None\n",
    "                            try:\n",
    "                                org =  li_elements[li_ind].find_element(By.CLASS_NAME, \"t-bold\").text \n",
    "                            except:\n",
    "                                org = None\n",
    "                            try:\n",
    "                                duration = subliele[sub_ind].find_element(By.CLASS_NAME, \"t-14.t-normal.t-black--light\").text\n",
    "                            except:\n",
    "                                duration = None\n",
    "                            try:\n",
    "                                location = subliele[-1].find_elements(By.CLASS_NAME, \"t-14.t-normal.t-black--light\")\n",
    "                            except:\n",
    "                                location = None\n",
    "                            try:\n",
    "                                data['title_'+str(li_ind)+'_sub_'+str(sub_ind)] = title.split('\\n')[0]\n",
    "                            except:\n",
    "                                data['title_'+str(li_ind)+'_sub_'+str(sub_ind)] = None\n",
    "                            try:\n",
    "                                data['org_'+str(li_ind)+'_sub_'+str(sub_ind)] = org.split('\\n')[0]\n",
    "                            except:\n",
    "                                data['org_'+str(li_ind)+'_sub_'+str(sub_ind)] = None\n",
    "                            try:\n",
    "                                data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_duration'] = duration.split('\\n')[0]\n",
    "                            except:\n",
    "                                data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_duration'] = None\n",
    "                            try:\n",
    "                                data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_location'] = location[1].text.split('\\n')[0]\n",
    "                            except:\n",
    "                                data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_location'] = None\n",
    "                            \n",
    "                    else:         \n",
    "                        \n",
    "                        try:\n",
    "                            company_link = li_elements[li_ind].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                            companies.append(company_link)\n",
    "                        except:\n",
    "                            company_link = None\n",
    "                            companies.append(company_link)\n",
    "                            \n",
    "                        try:\n",
    "                            title = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-bold\").text \n",
    "                        except:\n",
    "                            title = None\n",
    "                        try:\n",
    "                            org = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal\").text\n",
    "                        except:\n",
    "                            org = None\n",
    "                        try:\n",
    "                            duration = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal.t-black--light\").text\n",
    "                        except:\n",
    "                            duration = None\n",
    "                        try:\n",
    "                            location = li_elements[li_ind].find_elements(By.CLASS_NAME, \"t-14.t-normal.t-black--light\")\n",
    "                        except:\n",
    "                            location = None\n",
    "                        try:\n",
    "                            data['title_'+str(li_ind)] = title.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['title_'+str(li_ind)] = None\n",
    "                        try:\n",
    "                            data['org_'+str(li_ind)] = org.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['org_'+str(li_ind)] = None\n",
    "                        try:\n",
    "                            data['job_'+str(li_ind)+'_duration'] = duration.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['job_'+str(li_ind)+'_duration'] = None\n",
    "                        try:\n",
    "                            data['job_'+str(li_ind)+'_location'] = location[1].text.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['job_'+str(li_ind)+'_location'] = None\n",
    "            except:\n",
    "                None\n",
    "        main.update(data)\n",
    "    #--------------------------------------Capture again to ensure no stopage----------------------------------------------------------------        \n",
    "\n",
    "    pvs_header_elements = driver.find_elements(By.CSS_SELECTOR, '.artdeco-card')\n",
    "\n",
    "    #--------------------------------------Education Card------------------------------------------------------------------------------------\n",
    "    if edu != None:\n",
    "        data = {}\n",
    "        all_ele = pvs_header_elements[edu].find_elements(By.XPATH, \".//*\")\n",
    "        footer = []\n",
    "        for ele in all_ele:\n",
    "            class_name = ele.get_attribute(\"class\")\n",
    "            footer.append(class_name)\n",
    "            \n",
    "        flag = 'n'\n",
    "        for i in footer:\n",
    "            if i != None:\n",
    "                if 'pvs-list__footer-wrapper' in i:\n",
    "                    flag = 'y'\n",
    "        \n",
    "        if flag == 'y':\n",
    "            explink = pvs_header_elements[edu].find_element(By.CLASS_NAME, \"pvs-list__footer-wrapper\").find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "            driver.get(explink)\n",
    "            time.sleep(7)\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"button[aria-label='Back to the main profile page']\")))\n",
    "            # pvs_list_outer_container = pvs_header_elements[exp].find_element(By.CSS_SELECTOR, \"div.pvs-list__outer-container\")\n",
    "            \n",
    "            li_elements = driver.find_elements(By.CSS_SELECTOR, \"li.artdeco-list__item\")\n",
    "            try: \n",
    "                for li_ind in range(len(li_elements)):\n",
    "                    try:\n",
    "                        institute = li_elements[li_ind].find_element(By.CSS_SELECTOR, \"div.display-flex > div.display-flex > div.display-flex > div.display-flex\").text\n",
    "                    except:\n",
    "                        institute = None\n",
    "                    try:\n",
    "                        digree = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal\").text\n",
    "                    except:\n",
    "                        digree = None\n",
    "                    try:\n",
    "                        duration = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal.t-black--light\").text\n",
    "                    except:\n",
    "                        duration = None\n",
    "                    try:\n",
    "                        data['institute_'+str(li_ind)] = institute.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['institute_'+str(li_ind)] = None\n",
    "                    try:\n",
    "                        data['digree_'+str(li_ind)] = digree.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['digree_'+str(li_ind)] = None\n",
    "                    try:\n",
    "                        data['digree_'+str(li_ind)+'_duration'] = duration.split('\\n')[0] \n",
    "                    except:\n",
    "                        data['digree_'+str(li_ind)+'_duration'] = None\n",
    "            except:\n",
    "                None\n",
    "            driver.back()\n",
    "            time.sleep((random.randint(7, 20)))\n",
    "        else:    \n",
    "            pvs_list_outer_container = pvs_header_elements[edu].find_element(By.CSS_SELECTOR, \"div.pvs-list__outer-container\")\n",
    "            ul = pvs_list_outer_container.find_element(By.CLASS_NAME, 'pvs-list')\n",
    "            li_elements = ul.find_elements(By.XPATH, './li')\n",
    "            try: \n",
    "                for li_ind in range(len(li_elements)):\n",
    "                    try:\n",
    "                        institute = li_elements[li_ind].find_element(By.CSS_SELECTOR, \"div.display-flex > div.display-flex > div.display-flex > div.display-flex\").text\n",
    "                    except:\n",
    "                        institute = None\n",
    "                    try:\n",
    "                        digree = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal\").text\n",
    "                    except:\n",
    "                        digree = None\n",
    "                    try:\n",
    "                        duration = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal.t-black--light\").text\n",
    "                    except:\n",
    "                        duration = None\n",
    "                    try:\n",
    "                        data['institute_'+str(li_ind)] = institute.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['institute_'+str(li_ind)] = None\n",
    "                    try:\n",
    "                        data['digree_'+str(li_ind)] = digree.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['digree_'+str(li_ind)] = None\n",
    "                    try:\n",
    "                        data['digree_'+str(li_ind)+'_duration'] = duration.split('\\n')[0] \n",
    "                    except:\n",
    "                        data['digree_'+str(li_ind)+'_duration'] = None\n",
    "            except:\n",
    "                None\n",
    "        main.update(data)\n",
    "    #--------------------------------------Capture again to ensure no stopage----------------------------------------------------------------        \n",
    "    pvs_header_elements = driver.find_elements(By.CSS_SELECTOR, '.artdeco-card')\n",
    "    #-----------------------------------------Skill----------------------------------------------------------------------------------------------------\n",
    "    if skil != None:\n",
    "            \n",
    "        pvs_header_elements = driver.find_elements(By.CSS_SELECTOR, '.artdeco-card')\n",
    "\n",
    "        data = {}\n",
    "        all_ele = pvs_header_elements[skil].find_elements(By.XPATH, \".//*\")\n",
    "        footer = []\n",
    "        for ele in all_ele:\n",
    "            class_name = ele.get_attribute(\"class\")\n",
    "            footer.append(class_name)\n",
    "        \n",
    "        flag = 'n'\n",
    "        for i in footer:\n",
    "            if i != None:\n",
    "                if 'pvs-list__footer-wrapper' in i:\n",
    "                    flag = 'y'\n",
    "        \n",
    "        if flag == 'y':\n",
    "            skillink = pvs_header_elements[skil].find_element(By.CSS_SELECTOR, \"a[id^='navigation-index-Show-all'][href*='skills']\").get_attribute(\"href\")\n",
    "            \n",
    "            driver.get(skillink)\n",
    "            time.sleep(6)\n",
    "            # wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"button[aria-label='Back to the main profile page']\")))\n",
    "\n",
    "            proper = driver.find_element(By.CSS_SELECTOR, \".artdeco-tabpanel.active.ember-view\")\n",
    "            \n",
    "            li_elements = proper.find_elements(By.CSS_SELECTOR, \"li.artdeco-list__item\")\n",
    "            for skind in range(len(li_elements)):\n",
    "                data['skill_'+str(skind)] = li_elements[skind].text.split('\\n')[0]\n",
    "\n",
    "        else:\n",
    "            pvs_list_outer_container = pvs_header_elements[skil].find_element(By.CSS_SELECTOR, \"div.pvs-list__outer-container\")\n",
    "            ul = pvs_list_outer_container.find_element(By.CLASS_NAME, 'pvs-list')\n",
    "            li_elements = ul.find_elements(By.XPATH, './li')\n",
    "            li_elements = [li for li in li_elements if not li.text[0].isdigit()]\n",
    "            li_elements = [li for li in li_elements if not li.text.startswith(\"Endor\")]\n",
    "            \n",
    "            for skind in range(len(li_elements)):\n",
    "                data['skill_'+str(skind)] = li_elements[skind].text.split('\\n')[0]\n",
    "        main.update(data)\n",
    "        \n",
    "    #---------------------------------------companies links---------------------------------------------------------------\n",
    "    if companies != []:\n",
    "            \n",
    "        data = {}\n",
    "        for compind in range(len(companies)):\n",
    "            if companies[compind] != None:\n",
    "                if len(companies[compind].split('/')) > 6:\n",
    "                    data['company_'+str(compind)+'_emp_count'] = None\n",
    "                    data['company_'+str(compind)+'_industry'] = None\n",
    "                else:\n",
    "                    try:\n",
    "                        driver.get(companies[compind]+'/people')\n",
    "                        time.sleep((random.randint(7, 20)))\n",
    "                        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"li.org-page-navigation__item\")))\n",
    "                        \n",
    "                        if 'unavailable' in driver.current_url:\n",
    "                            continue\n",
    "                                \n",
    "                        time.sleep(2)\n",
    "                        emp_count = driver.find_element(By.CSS_SELECTOR, \"h2.text-heading-xlarge\").text.strip()\n",
    "                        industry = driver.find_element(By.CSS_SELECTOR, \"div.org-top-card-summary-info-list__info-item\").text.strip()\n",
    "                        data['company_'+str(compind)+'_emp_count']=emp_count\n",
    "                        data['company_'+str(compind)+'_industry'] = industry\n",
    "                        \n",
    "                    except:\n",
    "                        None\n",
    "        main.update(data)\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    if main != {}:\n",
    "        tempdf = pd.DataFrame(main, index=[0])\n",
    "        tempfilename = 'Linkedin_data_edit.parquet'\n",
    "\n",
    "        save_data_to_disk(tempdf, tempfilename)\n",
    "        tempdf = pd.DataFrame()\n",
    "    \n",
    "    current_ind += 1\n",
    "    \n",
    "    with open('linkedin_compleation_new.txt', 'w') as file:\n",
    "        file.write(str(current_ind))  \n",
    "    print(f'\\rRunning: {runtill+1}, current ind: {current_ind}', end='')\n",
    "    runtill += 1  \n",
    "    if runtill == 80:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('Linkedin_Adeft_Extract_20240109.xlsx')\n",
    "# tempfilename = 'Linkedin_data_edit.parquet'\n",
    "# df.to_parquet(tempfilename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkeddf = pd.read_parquet('Linkedin_data_edit.parquet')\n",
    "len(linkeddf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_columns = linkeddf.select_dtypes(include=['float64'])\n",
    "linkeddf[float_columns.columns] = float_columns.astype(str)\n",
    "float_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempfilename = 'Linkedin_data_edit.parquet'\n",
    "linkeddf.to_parquet(tempfilename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3126 entries, 0 to 3125\n",
      "Columns: 718 entries, name to job_1_sub_15_location\n",
      "dtypes: object(718)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "linkeddf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = linkeddf.columns\n",
    "sortlist = []\n",
    "    # 'name', 'location',\n",
    "    # 'title', 'org', 'job_duration', 'job_location',\n",
    "    # 'institute', 'digree', 'digree_duration',\n",
    "    # 'skill',\n",
    "    # 'company_emp_count', 'company_industry',\n",
    "columns = linkeddf.columns\n",
    "def custom_sort_key(org):\n",
    "    parts = org.split('_')\n",
    "    org_number = int(parts[1])\n",
    "    sub_number = int(parts[3]) if len(parts) > 3 else 0\n",
    "    return org_number, sub_number\n",
    "def custom_sort_key_comp(org):\n",
    "    parts = org.split('_')\n",
    "    org_number = int(parts[1])\n",
    "    return org_number\n",
    "\n",
    "sortlist = []\n",
    "\n",
    "# Sorting by 'name' and 'location'\n",
    "sortlist.extend(sorted([col for col in columns if 'name' in col]))\n",
    "sortlist.extend(sorted([col for col in columns if 'location' == col]))\n",
    "\n",
    "# Sorting by 'title', 'org', 'job_duration', and 'job_location'\n",
    "title_cols = sorted([col for col in columns if 'title' in col], key=custom_sort_key)\n",
    "org_cols = sorted([col for col in columns if 'org' in col], key=custom_sort_key)\n",
    "job_duration_cols = sorted([col for col in columns if 'job' in col and 'duration' in col], key=custom_sort_key)\n",
    "job_location_cols = sorted([col for col in columns if 'job' in col and 'location' in col], key=custom_sort_key)\n",
    "\n",
    "for title_col, org_col, job_duration_col, job_location_col in zip(title_cols, org_cols, job_duration_cols, job_location_cols):\n",
    "    sortlist.extend([org_col, title_col, job_duration_col, job_location_col])\n",
    "    \n",
    "institute_cols = sorted([col for col in columns if 'institute' in col], key=custom_sort_key)\n",
    "degree_cols = sorted([col for col in columns if 'digree' in col and 'duration' not in col], key=custom_sort_key)\n",
    "degree_duration_cols = sorted([col for col in columns if 'digree' in col and 'duration' in col], key=custom_sort_key)\n",
    "\n",
    "for institute_col, degree_col, degree_duration_col in zip(institute_cols, degree_cols, degree_duration_cols):\n",
    "    sortlist.extend([institute_col, degree_col, degree_duration_col])\n",
    "\n",
    "skill_cols = sorted([col for col in columns if 'skill' in col], key=custom_sort_key)\n",
    "sortlist.extend(skill_cols)\n",
    "\n",
    "company_emp_count_col = sorted([col for col in columns if 'company' in col and 'emp' in col], key=custom_sort_key_comp)\n",
    "company_industry_col = sorted([col for col in columns if 'company' in col and 'industry' in col], key=custom_sort_key_comp)\n",
    "\n",
    "for emp_count_col, industry_col in zip(company_emp_count_col, company_industry_col):\n",
    "    sortlist.extend([emp_count_col, industry_col])\n",
    "\n",
    "linkeddf = linkeddf.reindex(columns = sortlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkeddf.drop_duplicates(inplace = True)\n",
    "linkeddf = linkeddf.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3104, 718)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkeddf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "digree_col = []\n",
    "for i in linkeddf.columns:\n",
    "    if i.startswith('dig') and 'duration' not in i:\n",
    "        digree_col.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (\n",
    "    linkeddf[digree_col].apply(lambda col: col.str.lower().str.contains('mba')).any(axis=1) |\n",
    "    (linkeddf[digree_col].apply(lambda col: col.str.lower().str.contains('master')).any(axis=1) &\n",
    "     linkeddf[digree_col].apply(lambda col: col.str.lower().str.contains('busin')).any(axis=1) &\n",
    "     linkeddf[digree_col].apply(lambda col: col.str.lower().str.contains('admin')).any(axis=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2397, 718)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkeddf[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 'McCombs, Foster, Rice, Kelley, Carey, Tepper, Insead, Cambridge, Oxford, London Business School, Wharton, Olin, Johnson, Stern, Fuqua, Kellogg, Booth, melbourne business school, nanyang, NUS, marshall, ross, owen, simon, Goizueta'\n",
    "lis = []\n",
    "for i in l.split(','):\n",
    "    lis.append(i.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "countlist = []\n",
    "for k,v in linkeddf[institute_cols].iterrows():\n",
    "    for i in v.values:\n",
    "        if type(i) != float and i != 'nan':\n",
    "            countlist.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = set()\n",
    "from collections import Counter\n",
    "dic = dict(Counter(countlist))\n",
    "for i in dic.keys():\n",
    "    if i != None:    \n",
    "        for j in lis:\n",
    "            if j in i.lower():\n",
    "                a = (i,dic[i])\n",
    "                l.add(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(l,columns=['val','count']).sort_values(by='count',ascending=False).to_excel('school_value_counts.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkeddf.drop_duplicates(inplace=True)\n",
    "# linkeddf.to_csv('Linkedin_data.csv',index = False)\n",
    "australia_timezone = pytz.timezone('Australia/Sydney')\n",
    "current_time = datetime.datetime.now(australia_timezone)\n",
    "filename = 'Linkedin_Adeft_Extract_'+ str(current_time.date()).replace('-', '')+'.xlsx'\n",
    "linkeddf.to_excel(filename,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://onedrive.live.com/?id=F87FC3AA6EB46E0%21207168&cid=0F87FC3AA6EB46E0'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://onedrive.live.com/?id=F87FC3AA6EB46E0%21207168&cid=0F87FC3AA6EB46E0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
