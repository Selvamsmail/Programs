{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import gdown\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_excel('Linkedin_cleaned_latest_mapped_cols.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW-y6xwsCgkd"
      },
      "outputs": [],
      "source": [
        "titlecols = [col for col in df.columns if 'title' in col]\n",
        "df['all_titles'] = df[titlecols].apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)#--------------------------------------remove punctuvation\n",
        "df.drop(columns=titlecols, inplace=True)\n",
        "\n",
        "org_cols = ([col for col in df.columns if 'org' in col])\n",
        "df['all_org_cols'] = df[org_cols].apply(lambda row: ','.join(row.dropna().astype(str)), axis=1)\n",
        "df.drop(columns=org_cols, inplace=True)\n",
        "\n",
        "job_location_cols = [col for col in df.columns if 'location' in col]\n",
        "df['all_loc_cols'] = df[job_location_cols].apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "df.drop(columns=job_location_cols, inplace=True)\n",
        "\n",
        "institute_cols = [col for col in df.columns if 'institute' in col]\n",
        "df['all_instutes'] = df[institute_cols].apply(lambda row: ','.join(row.dropna().astype(str)), axis=1)\n",
        "df.drop(columns=institute_cols, inplace=True)\n",
        "\n",
        "degree_cols = [col for col in df.columns if 'digree' in col and 'duration' not in col]\n",
        "df['all_degree'] = df[degree_cols].apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "df.drop(columns=degree_cols, inplace=True)\n",
        "\n",
        "# 'skill',\n",
        "# 'company_emp_count', 'company_industry',\n",
        "\n",
        "skil_col = [col for col in df.columns if 'skill' in col]\n",
        "# df['all_skills'] = df[skil_col].apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "df.drop(columns=skil_col, inplace=True)\n",
        "\n",
        "comp_emp_count = [col for col in df.columns if 'company' in col and 'emp' in col]            # how big are their company exp's so we are totaling the info.\n",
        "# comp_emp_count.append('employee_count')\n",
        "df['all_comp_emp_count'] = df[comp_emp_count].sum(axis=1)\n",
        "df.drop(columns=comp_emp_count, inplace=True) #not enough data\n",
        "\n",
        "comp_ind = [col for col in df.columns if 'company' in col and 'industry' in col]\n",
        "df['all_comp_ind'] = df[comp_ind].apply(lambda row: ' '.join(row.dropna().astype(str)), axis=1)\n",
        "df.drop(columns=comp_ind, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4ty5zhv2wCh"
      },
      "outputs": [],
      "source": [
        "df.to_csv('retrival_database.csv',index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvFRoAIgSa0A"
      },
      "outputs": [],
      "source": [
        "del df['name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FCvoLrwEgGC"
      },
      "outputs": [],
      "source": [
        "df = pd.get_dummies(df,columns = job_duration_cols)\n",
        "df = pd.get_dummies(df,columns = degree_duration_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_rUjFZESc2O"
      },
      "outputs": [],
      "source": [
        "df.iloc[:,75:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOm4RtEk2KWc"
      },
      "source": [
        "# vectorizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmdnZ9ar2Jlb"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "def vectorize_columns_method1(df, columns_to_vectorize):\n",
        "    tfidf_vectorizer_method1 = TfidfVectorizer(tokenizer=lambda x: x.split(','))\n",
        "    job_titles_method1 = df[columns_to_vectorize].apply(lambda row: ','.join(row), axis=1)\n",
        "    job_title_matrix_method1 = tfidf_vectorizer_method1.fit_transform(job_titles_method1)\n",
        "    job_title_vector_df_method1 = pd.DataFrame(job_title_matrix_method1.toarray(), columns=tfidf_vectorizer_method1.get_feature_names_out())\n",
        "    return job_title_vector_df_method1,tfidf_vectorizer_method1\n",
        "\n",
        "def vectorize_columns_method2(df, columns_to_vectorize):\n",
        "    tfidf_vectorizer_method2 = TfidfVectorizer()\n",
        "    job_titles_method2 = df[columns_to_vectorize].apply(lambda row: ' '.join(row), axis=1)\n",
        "    job_title_matrix_method2 = tfidf_vectorizer_method2.fit_transform(job_titles_method2)\n",
        "    job_title_vector_df_method2 = pd.DataFrame(job_title_matrix_method2.toarray(), columns=tfidf_vectorizer_method2.get_feature_names_out())\n",
        "    return job_title_vector_df_method2,tfidf_vectorizer_method2\n",
        "\n",
        "# 'all_titles', 'all_org_cols', 'all_loc_cols', 'all_instutes',\n",
        "#        'all_degree', 'all_comp_emp_count', 'all_comp_ind'\n",
        "\n",
        "columns_to_vectorize_1 = ['all_org_cols','all_instutes']\n",
        "columns_to_vectorize_2 = [ 'all_titles', 'all_loc_cols', 'all_degree', 'all_comp_ind']\n",
        "\n",
        "vectorized_df_method1,tfidf_vectorizer_method1 = vectorize_columns_method1(df, columns_to_vectorize_1)\n",
        "vectorized_df_method2,tfidf_vectorizer_method2 = vectorize_columns_method2(df, columns_to_vectorize_2)\n",
        "\n",
        "# Concatenate the vectorized DataFrames horizontally\n",
        "result_df = pd.concat([df, vectorized_df_method1, vectorized_df_method2], axis=1)\n",
        "\n",
        "# Drop the non-vectorized columns\n",
        "result_df = result_df.drop(columns=columns_to_vectorize_1)\n",
        "result_df = result_df.drop(columns=columns_to_vectorize_2)\n",
        "# Print the resulting DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpjfPrd0HBTd"
      },
      "outputs": [],
      "source": [
        "orgdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS6bPxMh1wbQ"
      },
      "outputs": [],
      "source": [
        "orgdf.to_csv('retrivaldata.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkjgU6bSIDwf"
      },
      "outputs": [],
      "source": [
        "info_df = result_df.count()\n",
        "info_df = pd.DataFrame({'Column': info_df.index, 'Non-Null Count': info_df.values})\n",
        "info_df = info_df.sort_values(by='Non-Null Count', ascending=False)\n",
        "info_df = info_df.reset_index(drop = True)\n",
        "info_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_tl68WQA56b"
      },
      "outputs": [],
      "source": [
        "result_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1WoaJQDUOZp"
      },
      "source": [
        "# ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhlzrZGJYLAo"
      },
      "outputs": [],
      "source": [
        "# # Step 1: Split the Data\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Assuming 'tfidf_df' is your TF-IDF vectorized DataFrame\n",
        "# x_train, x_test = train_test_split(tfidf_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Step 2: Train a Model (k-Nearest Neighbors)\n",
        "# from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# # Create the k-NN model\n",
        "# knn_model = NearestNeighbors(n_neighbors=5, algorithm='auto', metric='cosine')\n",
        "# knn_model.fit(x_train)\n",
        "\n",
        "# # Step 3: Generate Recommendations\n",
        "# # Assuming 'user_input' is the vectorized input of the user\n",
        "# # Find the top 4 most similar profiles for each user input\n",
        "# user_input = x_test.iloc[5]  # Change the index (5) to any user index you want to test\n",
        "# user_input = user_input.values.reshape(1, -1)  # Reshape to 2D array\n",
        "\n",
        "# # Find the top 4 most similar profiles for the specific user input\n",
        "# distances, indices = knn_model.kneighbors(user_input, n_neighbors=4)\n",
        "\n",
        "# # Get the indices of the most similar profiles for the specific user\n",
        "# top_4_indices = indices[0]\n",
        "\n",
        "# # Get the top 4 profiles for the specific user from the original DataFrame\n",
        "# top_4_profiles = df.iloc[top_4_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gmbvX_JOLlYy",
        "outputId": "a07695f8-357d-4bcd-8ac3-6be1b5701e0d"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-9631a79e2b2c>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mbest_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_neighbors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 30 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 684, in _fit_and_score\n    estimator.fit(X_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_unsupervised.py\", line 176, in fit\n    return self._fit(X)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\", line 491, in _fit\n    X = self._validate_data(X, accept_sparse=\"csr\", order=\"C\")\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 565, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: '11,194 employees'\n\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 684, in _fit_and_score\n    estimator.fit(X_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_unsupervised.py\", line 176, in fit\n    return self._fit(X)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\", line 491, in _fit\n    X = self._validate_data(X, accept_sparse=\"csr\", order=\"C\")\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 565, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 2070, in __array__\n    return np.asarray(self._values, dtype=dtype)\nValueError: could not convert string to float: '2 employees'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "x_train, x_test = train_test_split(result_df, test_size=0.25, random_state=42)\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "knn_model = NearestNeighbors(algorithm='auto', metric='cosine')\n",
        "param_grid = {'n_neighbors': [3, 5, 7, 10, 15, 20]}\n",
        "\n",
        "grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(x_train)\n",
        "\n",
        "best_k = grid_search.best_params_['n_neighbors']\n",
        "print(best_k)\n",
        "\n",
        "knn_model = NearestNeighbors(n_neighbors=best_k, algorithm='auto', metric='cosine')\n",
        "knn_model.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiTFhkq1paVH"
      },
      "outputs": [],
      "source": [
        "x_train[:1].to_csv('x_train.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdpt2lAWxvkQ"
      },
      "outputs": [],
      "source": [
        "x_train[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGcGV3bEdx4e"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pickle\n",
        "\n",
        "with open('/content/knn_model_linkedin.pkl', 'wb') as file:\n",
        "    pickle.dump(knn_model, file)\n",
        "\n",
        "files.download('/content/knn_model_linkedin.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUpuCM9lCDqF"
      },
      "outputs": [],
      "source": [
        "user_input = x_test.iloc[5]  # Change the index (5) to any user index you want to test\n",
        "user_input = user_input.values.reshape(1, -1)  # Reshape to 2D array\n",
        "\n",
        "distances, indices = knn_model.kneighbors(user_input, n_neighbors=4)\n",
        "print('distances ',distances)\n",
        "top_4_indices = indices[0]\n",
        "\n",
        "top_4_profiles = orgdf.iloc[top_4_indices]\n",
        "top_4_profiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFCj7LOoHykH"
      },
      "outputs": [],
      "source": [
        "indices[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-mrBBooUdVJ"
      },
      "outputs": [],
      "source": [
        "distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C013E0K4OtKG"
      },
      "outputs": [],
      "source": [
        "cosine_distances = [0.00345241, 0.00346511, 0.00361493, 0.00381158]\n",
        "cosine_similarity_scores = [1 - distance for distance in cosine_distances]\n",
        "\n",
        "print(\"Cosine Similarity Scores:\", cosine_similarity_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gggrcDA7HG1E"
      },
      "outputs": [],
      "source": [
        "x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-oiV50iee1H"
      },
      "outputs": [],
      "source": [
        "user_input = x_test.iloc[10]\n",
        "user_input = user_input.values.reshape(1, -1)  # Reshape to 2D array\n",
        "\n",
        "# Find the top 4 most similar profiles for the specific user input\n",
        "distances, indices = knn_model.kneighbors(user_input, n_neighbors=4)\n",
        "\n",
        "# Get the indices of the most similar profiles for the specific user\n",
        "top_4_indices = indices[0]\n",
        "\n",
        "# Get the top 4 profiles for the specific user from the original DataFrame\n",
        "top_4_profiles = orgdf.iloc[top_4_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IDH5CXVCR_D"
      },
      "outputs": [],
      "source": [
        "top_4_profiles = top_4_profiles.dropna(axis=1, how='all')\n",
        "top_4_profiles = top_4_profiles.loc[:, (top_4_profiles != 0.0).any()]\n",
        "top_4_profiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-irlPojhIuO"
      },
      "outputs": [],
      "source": [
        "row_index = 220\n",
        "row_df = orgdf.iloc[row_index].to_frame().T\n",
        "row_df = row_df.dropna(axis=1, how='all')\n",
        "row_df = row_df.loc[:, (row_df != 0.0).any()]\n",
        "row_df.to_csv('input.csv',index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaWaif4FlVwH"
      },
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSuRRm_aEq1U"
      },
      "outputs": [],
      "source": [
        "row_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhuqWHanEzU9"
      },
      "outputs": [],
      "source": [
        "distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVcfhwv2b4GG"
      },
      "outputs": [],
      "source": [
        "top_4_profiles.to_csv('top_4_profiles.csv',index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LA8yXjINPcHW",
        "gCUktmHMCtlQ",
        "qpNo9YhfuQqh"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
