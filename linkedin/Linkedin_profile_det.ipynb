{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pytz\n",
    "import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_setup():# Assigning a Headless Firefox Driver\n",
    "  options = webdriver.FirefoxOptions()\n",
    "  options.binary_location = 'C:/Program Files/Mozilla Firefox/firefox.exe'  # Path to Chrome executable\n",
    "  options.add_argument('E:/Programs/geckodriver.exe')\n",
    "  # options.add_argument('--headless')\n",
    "  options.add_argument('--no-sandbox')\n",
    "  options.add_argument('--disable-dev-shm-usage')\n",
    "  driver = webdriver.Firefox(options=options)\n",
    "  return driver\n",
    "\n",
    "def save_data_to_disk(data, filename):\n",
    "    if os.path.isfile(filename):\n",
    "        existing_df = pd.read_csv(filename,)#encoding='ISO-8859-1')\n",
    "        data = pd.concat([existing_df, data], ignore_index=True)\n",
    "        os.remove(filename)\n",
    "        data.to_csv(filename,index=False)\n",
    "    else:\n",
    "        data.to_csv(filename, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of firefox cannot be detected. Trying with latest driver version\n"
     ]
    }
   ],
   "source": [
    "driver = driver_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.get(f\"https://www.linkedin.com/authwall?trk=qf&original_referer=&sessionRedirect=https%3A%2F%2Fwww.linkedin.com%2F\")\n",
    "Sign_in_button = driver.find_element(By.XPATH, \"/html/body/div/main/div/form/p/button\").click()\n",
    "\n",
    "email_phone = driver.find_element(By.XPATH, '//*[@id=\"session_key\"]')\n",
    "password = driver.find_element(By.XPATH, '//*[@id=\"session_password\"]')\n",
    "email_phone.send_keys(\"pannersmail@gmail.com\")\n",
    "# email_phone.send_keys(\"r.panneerselvam@firebird.net.in\")\n",
    "password.send_keys(\"Mk90473@yahoo.com\")\n",
    "\n",
    "submit_button = driver.find_element(By.XPATH, \"/html/body/div/main/div/div/form[1]/div[2]/button\")\n",
    "submit_button.click()\n",
    "\n",
    "wait = WebDriverWait(driver, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://www.linkedin.com/search/results/people/?currentCompany=%5B%2228133041%22%5D&keywords=%22talent%20acquisition%22&origin=GLOBAL_SEARCH_HEADER&sid=Q9J'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 3"
     ]
    }
   ],
   "source": [
    "save = 1\n",
    "pg = 1\n",
    "links= []\n",
    "# while True:    \n",
    "\n",
    "    # time.sleep(5)\n",
    "\n",
    "li_elements = driver.find_elements(By.CLASS_NAME, \"reusable-search__result-container\")\n",
    "for li in li_elements:\n",
    "    member_name = driver.execute_script('return arguments[0].querySelector(\"span.entity-result__title-text.t-16\").innerText;', li)\n",
    "    title = li.find_element(By.CSS_SELECTOR, 'div.entity-result__primary-subtitle').text\n",
    "    link = li.find_element(By.CSS_SELECTOR, 'a.app-aware-link').get_attribute('href')\n",
    "\n",
    "    tempdf = pd.DataFrame({'Name': member_name,'Title': title,'Profile_link':link},index=[0])\n",
    "    if not tempdf.empty:\n",
    "        print(f'\\rProgress: {save}', end='')\n",
    "        save+=1\n",
    "        tempfilename = 'names_and_titles.csv'\n",
    "\n",
    "        save_data_to_disk(tempdf, tempfilename)\n",
    "        tempdf = pd.DataFrame()\n",
    "    # pg += 1\n",
    "\n",
    "    # if pg > 90:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('names_and_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name'] = df['Name'].apply(lambda x: x.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('linkedin_profile_info.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Title', 'Company', 'Profile_link'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,v in df.iterrows():\n",
    "#     name = v['Name'].split('\\n')[0]\n",
    "#     print(i,name,v['Profile_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Profile_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rakesh Kumar</td>\n",
       "      <td>Assistant Manager - HR &amp; Admin. Enerzinx India...</td>\n",
       "      <td>ENERZINX</td>\n",
       "      <td>https://www.linkedin.com/in/rakesh-kumar-18b55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gayatri Suryavanshi</td>\n",
       "      <td>Talent Acquistion Specialist at BMI</td>\n",
       "      <td>Burns &amp; Mcdonnell</td>\n",
       "      <td>https://www.linkedin.com/in/gayatri-suryavansh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhagyashree Zade</td>\n",
       "      <td>Talent Acquisition | Human Resources - Burns &amp;...</td>\n",
       "      <td>Burns &amp; Mcdonnell</td>\n",
       "      <td>https://www.linkedin.com/in/bhagyashree-zade-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ashuta Shetty</td>\n",
       "      <td>Talent acquisition</td>\n",
       "      <td>Burns &amp; Mcdonnell</td>\n",
       "      <td>https://www.linkedin.com/in/ashuta-shetty-4a02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Konark Karkar</td>\n",
       "      <td>All things talent at Burns &amp; McDonnell, India....</td>\n",
       "      <td>Burns &amp; Mcdonnell</td>\n",
       "      <td>https://www.linkedin.com/in/konark-karkar-a229...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Muthuraj Nadar</td>\n",
       "      <td>Deputy Manager - Human Resources</td>\n",
       "      <td>Sterling wilson</td>\n",
       "      <td>https://www.linkedin.com/in/muthuraj-nadar-190...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>ARUPJYOTI SHARMA</td>\n",
       "      <td>Renewable Energy - Africa, Gulf &amp; India(w)</td>\n",
       "      <td>Sterling wilson</td>\n",
       "      <td>https://www.linkedin.com/in/arupjyoti-sharma-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Syam Mohan V P</td>\n",
       "      <td>Senior Manager - Business HR at Sterling and W...</td>\n",
       "      <td>Sterling wilson</td>\n",
       "      <td>https://www.linkedin.com/in/syam-mohan-v-p-104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Niraj Kayastha</td>\n",
       "      <td>Talent Acquisition at L&amp;T S&amp;L Limited</td>\n",
       "      <td>L&amp;T Sargent &amp; Lundy</td>\n",
       "      <td>https://www.linkedin.com/in/niraj-kayastha-759...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Sheba Mathews</td>\n",
       "      <td>Assistant Manager - HR at L&amp;T-Sargent &amp; Lundy ...</td>\n",
       "      <td>L&amp;T Sargent &amp; Lundy</td>\n",
       "      <td>https://www.linkedin.com/in/sheba-mathews-a70b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name                                              Title  \\\n",
       "0           Rakesh Kumar  Assistant Manager - HR & Admin. Enerzinx India...   \n",
       "1    Gayatri Suryavanshi                Talent Acquistion Specialist at BMI   \n",
       "2       Bhagyashree Zade  Talent Acquisition | Human Resources - Burns &...   \n",
       "3          Ashuta Shetty                                 Talent acquisition   \n",
       "4          Konark Karkar  All things talent at Burns & McDonnell, India....   \n",
       "..                   ...                                                ...   \n",
       "154       Muthuraj Nadar                   Deputy Manager - Human Resources   \n",
       "155     ARUPJYOTI SHARMA         Renewable Energy - Africa, Gulf & India(w)   \n",
       "156       Syam Mohan V P  Senior Manager - Business HR at Sterling and W...   \n",
       "157       Niraj Kayastha              Talent Acquisition at L&T S&L Limited   \n",
       "158        Sheba Mathews  Assistant Manager - HR at L&T-Sargent & Lundy ...   \n",
       "\n",
       "                   Company                                       Profile_link  \n",
       "0                 ENERZINX  https://www.linkedin.com/in/rakesh-kumar-18b55...  \n",
       "1        Burns & Mcdonnell  https://www.linkedin.com/in/gayatri-suryavansh...  \n",
       "2        Burns & Mcdonnell  https://www.linkedin.com/in/bhagyashree-zade-a...  \n",
       "3        Burns & Mcdonnell  https://www.linkedin.com/in/ashuta-shetty-4a02...  \n",
       "4        Burns & Mcdonnell  https://www.linkedin.com/in/konark-karkar-a229...  \n",
       "..                     ...                                                ...  \n",
       "154      Sterling wilson    https://www.linkedin.com/in/muthuraj-nadar-190...  \n",
       "155      Sterling wilson    https://www.linkedin.com/in/arupjyoti-sharma-1...  \n",
       "156      Sterling wilson    https://www.linkedin.com/in/syam-mohan-v-p-104...  \n",
       "157  L&T Sargent & Lundy    https://www.linkedin.com/in/niraj-kayastha-759...  \n",
       "158  L&T Sargent & Lundy    https://www.linkedin.com/in/sheba-mathews-a70b...  \n",
       "\n",
       "[159 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('linkedin_profile_with_emails.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss\n",
    "# si_si\n",
    "# si_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ENERZINX', 'Burns & Mcdonnell', 'Black & Veatch',\n",
       "       'Continuum Associates LLC', 'Customized Energy Solutions',\n",
       "       'Guidehouse', 'OATI', 'GE Energy', 'EATON', 'Ckinetics  ',\n",
       "       'Gensol', 'Sterling wilson  ', 'L&T Sargent & Lundy  '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Company'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in df[df['Company'] == 'Burns & Mcdonnell'][['Name','Profile_link']].iterrows():\n",
    "#     print(v.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ENERZINX', 'Burns & Mcdonnell', 'Black & Veatch',\n",
       "       'Continuum Associates LLC', 'Customized Energy Solutions',\n",
       "       'Guidehouse', 'OATI', 'GE Energy', 'EATON', 'Ckinetics  ',\n",
       "       'Gensol', 'Sterling wilson  ', 'L&T Sargent & Lundy  '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Company'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in df[df['Company'] == 'Burns & Mcdonnell']['Name'].apply(lambda x: x.replace('.','').split(' ')[:2]):\n",
    "    l.append(i[0][0]+'_'+i[1]+'@burnsmcd.in')\n",
    "    l.append(i[0][0]+i[1]+'@burnsmcd.in')\n",
    "    l.append(i[0]+'_'+i[1]+'@burnsmcd.in')\n",
    "emailsdf = pd.DataFrame(l,columns=['email']).to_excel('emails.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in df[df['Company'] == 'Black & Veatch']['Name'].apply(lambda x: x.replace('.','').split(' ')[:2]):\n",
    "    l.append(i[0][0]+'_'+i[1]+'@bv.com')\n",
    "    l.append(i[0][0]+i[1]+'@bv.com')\n",
    "    l.append(i[0]+'_'+i[1]+'@bv.com')\n",
    "emailsdf = pd.DataFrame(l,columns=['email']).to_excel('emails.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in df[df['Company'] == 'Guidehouse']['Name'].apply(lambda x: x.replace('.','').split(' ')[:2]):\n",
    "    l.append(i[0][0]+'_'+i[1]+'@guidehouse.com')\n",
    "    l.append(i[0][0]+i[1]+'@guidehouse.com')\n",
    "    l.append(i[0]+'_'+i[1]+'@guidehouse.com')\n",
    "emailsdf = pd.DataFrame(l,columns=['email']).to_excel('emails.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in df[df['Company'] == 'OATI']['Name'].apply(lambda x: x.replace('.','').split(' ')[:2]):\n",
    "    l.append(i[0][0]+'_'+i[1]+'@oati.net')\n",
    "    l.append(i[0][0]+i[1]+'@oati.net')\n",
    "    l.append(i[0]+'_'+i[1]+'@oati.net')\n",
    "emailsdf = pd.DataFrame(l,columns=['email']).to_excel('emails.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34    [Anupam, Pande]\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Company'] == 'Continuum Associates LLC']['Name'].apply(lambda x: x.replace('.','').split(' ')[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_email_combinations(name, domain):\n",
    "    name_parts = name.split(' ')\n",
    "    first_name = name_parts[0]\n",
    "    last_name = name_parts[1]\n",
    "\n",
    "    combinations = {\n",
    "        f'{first_name[0]}_{last_name}{domain}',\n",
    "        f'{first_name[0]}{last_name}{domain}',\n",
    "        f'{first_name}_{last_name}{domain}',\n",
    "        f'{first_name}.{last_name}{domain}',\n",
    "        f'{last_name}_{first_name}{domain}',\n",
    "        f'{last_name}.{first_name}{domain}',\n",
    "        f'{first_name}.{last_name[0]}{domain}',\n",
    "        f'{last_name}.{first_name[0]}{domain}',\n",
    "        f'{first_name[0]}{last_name[0]}{domain}',\n",
    "        f'{first_name}{last_name[0]}{domain}',\n",
    "        f'{last_name[0]}{first_name[0]}{domain}',\n",
    "        f'{last_name[0]}{first_name}{domain}',\n",
    "    }\n",
    "\n",
    "    return combinations\n",
    "\n",
    "name = 'Pooja Dhingiya'\n",
    "domain = '@siemens.com'\n",
    "email_combinations = generate_email_combinations(name, domain)\n",
    "pd.DataFrame(email_combinations,columns=['email']).to_excel('emails.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of firefox cannot be detected. Trying with latest driver version\n"
     ]
    }
   ],
   "source": [
    "driver = driver_setup()\n",
    "driver.get(f\"https://tools.emailhippo.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Programs\\linkedin\\Linkedin_profile_det.ipynb Cell 15\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Programs/linkedin/Linkedin_profile_det.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m email_input\u001b[39m.\u001b[39msend_keys(email)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Programs/linkedin/Linkedin_profile_det.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m button \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mCLASS_NAME, \u001b[39m'\u001b[39m\u001b[39mbtn-secondary\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mclick()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Programs/linkedin/Linkedin_profile_det.ipynb#X51sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m4\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in emailsdf['email']:    \n",
    "    time.sleep(2)\n",
    "    email = i\n",
    "    email_input = driver.find_element(By.ID, 'input-email-address')\n",
    "    email_input.send_keys(email)\n",
    "    button = driver.find_element(By.CLASS_NAME, 'btn-secondary').click()\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhishek Oza\\nView Abhishek Ozaâ€™s profile\\n \\n...</td>\n",
       "      <td>Head Talent Acquisition and Leadership Hiring ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0  Abhishek Oza\\nView Abhishek Ozaâ€™s profile\\n \\n...   \n",
       "\n",
       "                                               Title  \n",
       "0  Head Talent Acquisition and Leadership Hiring ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "https://www.linkedin.com/search/results/people/?currentCompany=keywords=resource%20energy%20hr\n",
    "\n",
    "https://www.linkedin.com/search/results/people/?currentCompany=%5B%2253422094%22%2C%22783377%22%2C%22233894%22%2C%22407491%22%2C%2256649373%22%2C%2213310503%22%2C%22164306%22%2C%22762368%22%2C%221042596%22%2C%222599%22%2C%221021%22%2C%2269475907%22%2C%2230093%22%2C%2233729759%22%2C%2273349%22%2C%2258335966%22%2C%2228974109%22%2C%2230754506%22%2C%2210658713%22%2C%221954461%22%2C%222115255%22%2C%2227140898%22%2C%2228133041%22%2C%2236021065%22%2C%2258335966%22%2C%2278437022%22%5D&geoUrn=%5B%22102713980%22%5D&keywords=%22talent%20acquisition%22%20%22head%22&origin=FACETED_SEARCH&sid=jiA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/in/prasadchandran?min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/in/tamilmani-selvan-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/in/shrutipy?miniProfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/in/siddharth-jain-71a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/in/swapnil-more-8b2a3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6115</th>\n",
       "      <td>https://www.linkedin.com/in/madhav-rane-345658...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6116</th>\n",
       "      <td>https://www.linkedin.com/in/vijay-jain-7474231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6117</th>\n",
       "      <td>https://www.linkedin.com/in/a-subramanian-44b9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>https://www.linkedin.com/in/satheesha-magaji-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119</th>\n",
       "      <td>https://www.linkedin.com/in/adarsh-nahata-4a34...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6120 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Link\n",
       "0     https://www.linkedin.com/in/prasadchandran?min...\n",
       "1     https://www.linkedin.com/in/tamilmani-selvan-1...\n",
       "2     https://www.linkedin.com/in/shrutipy?miniProfi...\n",
       "3     https://www.linkedin.com/in/siddharth-jain-71a...\n",
       "4     https://www.linkedin.com/in/swapnil-more-8b2a3...\n",
       "...                                                 ...\n",
       "6115  https://www.linkedin.com/in/madhav-rane-345658...\n",
       "6116  https://www.linkedin.com/in/vijay-jain-7474231...\n",
       "6117  https://www.linkedin.com/in/a-subramanian-44b9...\n",
       "6118  https://www.linkedin.com/in/satheesha-magaji-1...\n",
       "6119  https://www.linkedin.com/in/adarsh-nahata-4a34...\n",
       "\n",
       "[6120 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linksdf = pd.read_csv('links.csv')\n",
    "linksdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "linksdf.drop_duplicates(inplace=True)\n",
    "linksdf.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "linksdf.to_csv('Links.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/in/prasadchandran?min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/in/tamilmani-selvan-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/in/shrutipy?miniProfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/in/siddharth-jain-71a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/in/swapnil-more-8b2a3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6115</th>\n",
       "      <td>https://www.linkedin.com/in/madhav-rane-345658...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6116</th>\n",
       "      <td>https://www.linkedin.com/in/vijay-jain-7474231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6117</th>\n",
       "      <td>https://www.linkedin.com/in/a-subramanian-44b9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>https://www.linkedin.com/in/satheesha-magaji-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119</th>\n",
       "      <td>https://www.linkedin.com/in/adarsh-nahata-4a34...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6120 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Link\n",
       "0     https://www.linkedin.com/in/prasadchandran?min...\n",
       "1     https://www.linkedin.com/in/tamilmani-selvan-1...\n",
       "2     https://www.linkedin.com/in/shrutipy?miniProfi...\n",
       "3     https://www.linkedin.com/in/siddharth-jain-71a...\n",
       "4     https://www.linkedin.com/in/swapnil-more-8b2a3...\n",
       "...                                                 ...\n",
       "6115  https://www.linkedin.com/in/madhav-rane-345658...\n",
       "6116  https://www.linkedin.com/in/vijay-jain-7474231...\n",
       "6117  https://www.linkedin.com/in/a-subramanian-44b9...\n",
       "6118  https://www.linkedin.com/in/satheesha-magaji-1...\n",
       "6119  https://www.linkedin.com/in/adarsh-nahata-4a34...\n",
       "\n",
       "[6120 rows x 1 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linksdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('linkedin_compleation_new.txt', 'r') as file:\n",
    "    current_ind = int(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runtill = 0\n",
    "\n",
    "pbar = tqdm(total=83, desc='Scrapeing', unit='profile')\n",
    "\n",
    "for linkind in range(current_ind, len(linksdf)):\n",
    "    pbar.update(1)\n",
    "\n",
    "    companies = []\n",
    "    \n",
    "    driver.get(linksdf['Link'][linkind])\n",
    "    time.sleep((random.randint(7, 20)))\n",
    "    main = {} \n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    data = {}\n",
    "    try:\n",
    "        name = h1_element = driver.find_element(By.CLASS_NAME, \"text-heading-xlarge\").text\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        # driver.find_element(By.CSS_SELECTOR, '[id^=\"ember\"] > div.ph5 > div.mt2.relative > div.pv-text-details__left-panel.mt2 > span.text-body-small.inline.t-black--light.break-words').text\n",
    "        location = driver.find_element(By.CSS_SELECTOR, 'span.text-body-small.inline.t-black--light.break-words').text\n",
    "    except:\n",
    "        location = None\n",
    "    try:\n",
    "        data['name']=name\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        data['location']=location\n",
    "    except:\n",
    "        None\n",
    "    main.update(data)\n",
    "    #-----------------------------------------follow-------------------------------------------------------------\n",
    "    # try:\n",
    "    #     followbutton = driver.find_element(By.CLASS_NAME, \"pvs-profile-actions__action\")\n",
    "    #     followbutton.click()\n",
    "    # except:\n",
    "    #     None    \n",
    "    #-----------------------------------get relevant cards-------------------------------------------------------------------\n",
    "    pvs_header_elements = driver.find_elements(By.CSS_SELECTOR, '.artdeco-card')\n",
    "\n",
    "    pvs_header_ind = {\n",
    "        'exp': None,\n",
    "        'edu': None,\n",
    "        'skil': None\n",
    "    }\n",
    "\n",
    "    for eleind in range(len(pvs_header_elements)):\n",
    "        try:\n",
    "            t = pvs_header_elements[eleind].find_element(By.CLASS_NAME, \"pvs-header__title-container\").text.lower()\n",
    "            if ('experience' in t):\n",
    "                pvs_header_ind['exp'] = eleind\n",
    "            elif ('education' in t):\n",
    "                pvs_header_ind['edu'] = eleind\n",
    "            elif ('skills' in t):\n",
    "                pvs_header_ind['skil'] = eleind\n",
    "        except:\n",
    "            None\n",
    "    exp = pvs_header_ind['exp']\n",
    "    edu = pvs_header_ind['edu']\n",
    "    skil = pvs_header_ind['skil']\n",
    "\n",
    "    #---------------------------------------Experience Card----------------------------------------------------------------\n",
    "    if exp != None:\n",
    "        data={}\n",
    "\n",
    "        all_ele = pvs_header_elements[exp].find_elements(By.XPATH, \".//*\")\n",
    "        footer = []\n",
    "        for ele in all_ele:\n",
    "            class_name = ele.get_attribute(\"class\")\n",
    "            footer.append(class_name)\n",
    "            \n",
    "        if 'pvs-list__footer-wrapper' in footer:\n",
    "            explink = pvs_header_elements[exp].find_element(By.CLASS_NAME, \"pvs-list__footer-wrapper\").find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "            driver.get(explink)\n",
    "            time.sleep(10)\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"button[aria-label='Back to the main profile page']\")))\n",
    "            # pvs_list_outer_container = pvs_header_elements[exp].find_element(By.CSS_SELECTOR, \"div.pvs-list__outer-container\")\n",
    "            \n",
    "            li_elements = driver.find_elements(By.CSS_SELECTOR, \"li.artdeco-list__item\")\n",
    "            \n",
    "            for li_ind in range(len(li_elements)):     \n",
    "                add_du_pvs = 0\n",
    "                \n",
    "                node_elements = li_elements[li_ind].find_elements(By.TAG_NAME, \"span\")\n",
    "                node = []\n",
    "                for element in node_elements:\n",
    "                    class_name = element.get_attribute(\"class\")\n",
    "                    node.append(class_name)\n",
    "                if 'pvs-entity__path-node' in node:\n",
    "                    subliele = li_elements[li_ind].find_elements(By.CLASS_NAME, \"pvs-list__paged-list-item\")\n",
    "                    \n",
    "                    try:\n",
    "                        company_link = li_elements[li_ind].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                        companies.append(company_link)\n",
    "                    except:\n",
    "                        company_link = None\n",
    "                        companies.append(company_link)\n",
    "                        \n",
    "                    for sub_ind in range(len(subliele)):\n",
    "                        \n",
    "                        try:\n",
    "                            title = subliele[sub_ind].find_element(By.CLASS_NAME, \"t-bold\").text\n",
    "                        except:\n",
    "                            title = None\n",
    "                        try:\n",
    "                            org =  li_elements[li_ind].find_element(By.CLASS_NAME, \"t-bold\").text \n",
    "                        except:\n",
    "                            org = None\n",
    "                        try:\n",
    "                            duration = subliele[sub_ind].find_element(By.CLASS_NAME, \"t-14.t-normal.t-black--light\").text\n",
    "                        except:\n",
    "                            duration = None\n",
    "                        try:\n",
    "                            location = subliele[-1].find_elements(By.CLASS_NAME, \"t-14.t-normal.t-black--light\")\n",
    "                        except:\n",
    "                            location = None\n",
    "                        try:\n",
    "                            data['title_'+str(li_ind)+'_sub_'+str(sub_ind)] = title.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['title_'+str(li_ind)+'_sub_'+str(sub_ind)] = None\n",
    "                        try:\n",
    "                            data['org_'+str(li_ind)+'_sub_'+str(sub_ind)] = org.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['org_'+str(li_ind)+'_sub_'+str(sub_ind)] = None\n",
    "                        try:\n",
    "                            data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_duration'] = duration.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_duration'] = None\n",
    "                        try:\n",
    "                            data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_location'] = location[1].text.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_location'] = None\n",
    "                        \n",
    "                else:         \n",
    "                    \n",
    "                    try:\n",
    "                        company_link = li_elements[li_ind].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                        companies.append(company_link)\n",
    "                    except:\n",
    "                        company_link = None\n",
    "                        companies.append(company_link)\n",
    "                        \n",
    "                    try:\n",
    "                        title = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-bold\").text \n",
    "                    except:\n",
    "                        title = None\n",
    "                    try:\n",
    "                        org = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal\").text\n",
    "                    except:\n",
    "                        org = None\n",
    "                    try:\n",
    "                        duration = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal.t-black--light\").text\n",
    "                    except:\n",
    "                        duration = None\n",
    "                    try:\n",
    "                        location = li_elements[li_ind].find_elements(By.CLASS_NAME, \"t-14.t-normal.t-black--light\")\n",
    "                    except:\n",
    "                        location = None\n",
    "                    try:\n",
    "                        data['title_'+str(li_ind)] = title.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['title_'+str(li_ind)] = None\n",
    "                    try:\n",
    "                        data['org_'+str(li_ind)] = org.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['org_'+str(li_ind)] = None\n",
    "                    try:\n",
    "                        data['job_'+str(li_ind)+'_duration'] = duration.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['job_'+str(li_ind)+'_duration'] = None\n",
    "                    try:\n",
    "                        data['job_'+str(li_ind)+'_location'] = location[1].text.split('\\n')[0]\n",
    "                    except:\n",
    "                        data['job_'+str(li_ind)+'_location'] = None\n",
    "\n",
    "            driver.back()\n",
    "            time.sleep((random.randint(7, 20)))\n",
    "        else:\n",
    "            try:\n",
    "                pvs_list_outer_container = pvs_header_elements[exp].find_element(By.CSS_SELECTOR, \"div.pvs-list__outer-container\")\n",
    "                li_elements = pvs_list_outer_container.find_elements(By.CSS_SELECTOR, \"ul.pvs-list > li\")\n",
    "                li_elements = [li for li in li_elements if not li.text.startswith(\"Skills\")]\n",
    "                \n",
    "                for li_ind in range(len(li_elements)):     \n",
    "                    add_du_pvs = 0\n",
    "                    \n",
    "                    node_elements = li_elements[li_ind].find_elements(By.TAG_NAME, \"span\")\n",
    "                    node = []\n",
    "                    for element in node_elements:\n",
    "                        class_name = element.get_attribute(\"class\")\n",
    "                        node.append(class_name)\n",
    "                    if 'pvs-entity__path-node' in node:\n",
    "                        subliele = li_elements[li_ind].find_elements(By.CLASS_NAME, \"pvs-list__paged-list-item\")\n",
    "                        \n",
    "                        try:\n",
    "                            company_link = li_elements[li_ind].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                            companies.append(company_link)\n",
    "                        except:\n",
    "                            company_link = None\n",
    "                            companies.append(company_link)\n",
    "                            \n",
    "                        for sub_ind in range(len(subliele)):\n",
    "                            \n",
    "                            try:\n",
    "                                title = subliele[sub_ind].find_element(By.CLASS_NAME, \"t-bold\").text\n",
    "                            except:\n",
    "                                title = None\n",
    "                            try:\n",
    "                                org =  li_elements[li_ind].find_element(By.CLASS_NAME, \"t-bold\").text \n",
    "                            except:\n",
    "                                org = None\n",
    "                            try:\n",
    "                                duration = subliele[sub_ind].find_element(By.CLASS_NAME, \"t-14.t-normal.t-black--light\").text\n",
    "                            except:\n",
    "                                duration = None\n",
    "                            try:\n",
    "                                location = subliele[-1].find_elements(By.CLASS_NAME, \"t-14.t-normal.t-black--light\")\n",
    "                            except:\n",
    "                                location = None\n",
    "                            try:\n",
    "                                data['title_'+str(li_ind)+'_sub_'+str(sub_ind)] = title.split('\\n')[0]\n",
    "                            except:\n",
    "                                data['title_'+str(li_ind)+'_sub_'+str(sub_ind)] = None\n",
    "                            try:\n",
    "                                data['org_'+str(li_ind)+'_sub_'+str(sub_ind)] = org.split('\\n')[0]\n",
    "                            except:\n",
    "                                data['org_'+str(li_ind)+'_sub_'+str(sub_ind)] = None\n",
    "                            try:\n",
    "                                data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_duration'] = duration.split('\\n')[0]\n",
    "                            except:\n",
    "                                data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_duration'] = None\n",
    "                            try:\n",
    "                                data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_location'] = location[1].text.split('\\n')[0]\n",
    "                            except:\n",
    "                                data['job_'+str(li_ind)+'_sub_'+str(sub_ind)+'_location'] = None\n",
    "                            \n",
    "                    else:         \n",
    "                        \n",
    "                        try:\n",
    "                            company_link = li_elements[li_ind].find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                            companies.append(company_link)\n",
    "                        except:\n",
    "                            company_link = None\n",
    "                            companies.append(company_link)\n",
    "                            \n",
    "                        try:\n",
    "                            title = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-bold\").text \n",
    "                        except:\n",
    "                            title = None\n",
    "                        try:\n",
    "                            org = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal\").text\n",
    "                        except:\n",
    "                            org = None\n",
    "                        try:\n",
    "                            duration = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal.t-black--light\").text\n",
    "                        except:\n",
    "                            duration = None\n",
    "                        try:\n",
    "                            location = li_elements[li_ind].find_elements(By.CLASS_NAME, \"t-14.t-normal.t-black--light\")\n",
    "                        except:\n",
    "                            location = None\n",
    "                        try:\n",
    "                            data['title_'+str(li_ind)] = title.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['title_'+str(li_ind)] = None\n",
    "                        try:\n",
    "                            data['org_'+str(li_ind)] = org.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['org_'+str(li_ind)] = None\n",
    "                        try:\n",
    "                            data['job_'+str(li_ind)+'_duration'] = duration.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['job_'+str(li_ind)+'_duration'] = None\n",
    "                        try:\n",
    "                            data['job_'+str(li_ind)+'_location'] = location[1].text.split('\\n')[0]\n",
    "                        except:\n",
    "                            data['job_'+str(li_ind)+'_location'] = None\n",
    "            except:\n",
    "                None\n",
    "        main.update(data)\n",
    "    #--------------------------------------Capture again to ensure no stopage----------------------------------------------------------------        \n",
    "    \n",
    "    pvs_header_elements = driver.find_elements(By.CSS_SELECTOR, '.artdeco-card')\n",
    "    \n",
    "    #--------------------------------------Education Card------------------------------------------------------------------------------------\n",
    "    if edu != None:\n",
    "        pvs_list_outer_container = pvs_header_elements[edu].find_element(By.CSS_SELECTOR, \"div.pvs-list__outer-container\")\n",
    "        li_elements = pvs_list_outer_container.find_elements(By.CSS_SELECTOR, \"ul.pvs-list > li\")\n",
    "        data = {}\n",
    "        try: \n",
    "            for li_ind in range(len(li_elements)):\n",
    "                try:\n",
    "                    institute = li_elements[li_ind].find_element(By.CSS_SELECTOR, \"div.display-flex > div.display-flex > div.display-flex > div.display-flex\").text\n",
    "                except:\n",
    "                    institute = None\n",
    "                try:\n",
    "                    digree = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal\").text\n",
    "                except:\n",
    "                    digree = None\n",
    "                try:\n",
    "                    duration = li_elements[li_ind].find_element(By.CLASS_NAME, \"t-14.t-normal.t-black--light\").text\n",
    "                except:\n",
    "                    duration = None\n",
    "                try:\n",
    "                    data['institute_'+str(li_ind)] = institute.split('\\n')[0]\n",
    "                except:\n",
    "                    data['institute_'+str(li_ind)] = None\n",
    "                try:\n",
    "                    data['digree_'+str(li_ind)] = digree.split('\\n')[0]\n",
    "                except:\n",
    "                    data['digree_'+str(li_ind)] = None\n",
    "                try:\n",
    "                    data['digree_'+str(li_ind)+'_duration'] = duration.split('\\n')[0] \n",
    "                except:\n",
    "                    data['digree_'+str(li_ind)+'_duration'] = None\n",
    "        except:\n",
    "            None\n",
    "        main.update(data)\n",
    "    #-----------------------------------------Skill----------------------------------------------------------------------------------------------------\n",
    "    if skil != None:\n",
    "            \n",
    "        pvs_header_elements = driver.find_elements(By.CSS_SELECTOR, '.artdeco-card')\n",
    "\n",
    "        data = {}\n",
    "        all_ele = pvs_header_elements[skil].find_elements(By.XPATH, \".//*\")\n",
    "        footer = []\n",
    "        for ele in all_ele:\n",
    "            class_name = ele.get_attribute(\"class\")\n",
    "            footer.append(class_name)\n",
    "        if 'pvs-list__footer-wrapper' in footer:\n",
    "            \n",
    "            skillink = pvs_header_elements[skil].find_element(By.CSS_SELECTOR, \"a[id^='navigation-index-Show-all'][href*='skills']\").get_attribute(\"href\")\n",
    "            \n",
    "            driver.get(skillink)\n",
    "            time.sleep(6)\n",
    "            # wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"button[aria-label='Back to the main profile page']\")))\n",
    "\n",
    "            proper = driver.find_element(By.CSS_SELECTOR, \".artdeco-tabpanel.active.ember-view\")\n",
    "            \n",
    "            li_elements = proper.find_elements(By.CSS_SELECTOR, \"li.artdeco-list__item\")\n",
    "            for skind in range(len(li_elements)):\n",
    "                data['skill_'+str(skind)] = li_elements[skind].text.split('\\n')[0]\n",
    "\n",
    "        else:\n",
    "            pvs_list_outer_container = pvs_header_elements[skil].find_element(By.CSS_SELECTOR, \"div.pvs-list__outer-container\")\n",
    "            li_elements = pvs_list_outer_container.find_elements(By.CSS_SELECTOR, \"ul.pvs-list > li\")\n",
    "            li_elements = [li for li in li_elements if not li.text[0].isdigit()]\n",
    "            li_elements = [li for li in li_elements if not li.text.startswith(\"Endor\")]\n",
    "            \n",
    "            for skind in range(len(li_elements)):\n",
    "                data['skill_'+str(skind)] = li_elements[skind].text.split('\\n')[0]\n",
    "        main.update(data)\n",
    "        \n",
    "    #---------------------------------------companies links---------------------------------------------------------------\n",
    "    if companies != []:\n",
    "            \n",
    "        data = {}\n",
    "        for compind in range(len(companies)):\n",
    "            if companies[compind] != None:\n",
    "                if len(companies[compind].split('/')) > 6:\n",
    "                    data['company_'+str(compind)+'_emp_count'] = None\n",
    "                    data['company_'+str(compind)+'_industry'] = None\n",
    "                else:\n",
    "                    try:\n",
    "                        driver.get(companies[compind]+'/people')\n",
    "                        time.sleep((random.randint(7, 20)))\n",
    "                        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"li.org-page-navigation__item\")))\n",
    "                        \n",
    "                        if 'unavailable' in driver.current_url:\n",
    "                            continue\n",
    "                                \n",
    "                        time.sleep(2)\n",
    "                        emp_count = driver.find_element(By.CSS_SELECTOR, \"h2.text-heading-xlarge\").text.strip()\n",
    "                        industry = driver.find_element(By.CSS_SELECTOR, \"div.org-top-card-summary-info-list__info-item\").text.strip()\n",
    "                        data['company_'+str(compind)+'_emp_count']=emp_count\n",
    "                        data['company_'+str(compind)+'_industry'] = industry\n",
    "                        \n",
    "                    except:\n",
    "                        None\n",
    "        main.update(data)\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    if main != {}:\n",
    "        tempdf = pd.DataFrame(main, index=[0])\n",
    "        tempfilename = 'Linkedin_data_edit.csv'\n",
    "\n",
    "        save_data_to_disk(tempdf, tempfilename)\n",
    "        tempdf = pd.DataFrame()\n",
    "    \n",
    "    current_ind += 1\n",
    "    \n",
    "    with open('linkedin_compleation_new.txt', 'w') as file:\n",
    "        file.write(str(current_ind))  \n",
    "    print(runtill)\n",
    "    runtill += 1  \n",
    "    if runtill == 80:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company names are not capturing.\n",
    "# skills are bull shit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('Endorsed by Niraj Adatia who is highly skilled at this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PM\\AppData\\Local\\Temp\\ipykernel_27280\\1987237144.py:1: DtypeWarning: Columns (8,9,10,11,12,13,14,15,16,17,34,35,36,37,38,43,44,45,46,47,48,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,307,308,309,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,379,380,381,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,427,428,429,431,432,433,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,483,484,485,487,488,489,491,492,493,494,495,496,497,498,499,500,501,503,504,505,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,523,524,525) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  linkeddf = pd.read_csv('Linkedin_data_edit.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkeddf = pd.read_csv('Linkedin_data_edit.csv')\n",
    "len(linkeddf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_14_sub_0_location', 'job_14_sub_1_location',\n",
       "       'job_13_sub_0_location', 'job_13_sub_1_location',\n",
       "       'job_4_sub_5_location', 'job_15_sub_0_location',\n",
       "       'job_15_sub_1_location', 'job_10_sub_2_location',\n",
       "       'job_5_sub_3_location', 'job_7_sub_3_location', 'job_7_sub_4_location',\n",
       "       'job_16_sub_0_location', 'job_16_sub_1_location',\n",
       "       'job_4_sub_6_location', 'job_4_sub_7_location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_columns = linkeddf.select_dtypes(include=['float64'])\n",
    "linkeddf[float_columns.columns] = float_columns.astype(str)\n",
    "float_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempfilename = 'Linkedin_data_edit.csv'\n",
    "# linkeddf.to_csv(tempfilename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5674 entries, 0 to 5673\n",
      "Columns: 527 entries, name to job_4_sub_7_location\n",
      "dtypes: object(527)\n",
      "memory usage: 22.8+ MB\n"
     ]
    }
   ],
   "source": [
    "linkeddf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = linkeddf.columns\n",
    "sortlist = []\n",
    "    # 'name', 'location',\n",
    "    # 'title', 'org', 'job_duration', 'job_location',\n",
    "    # 'institute', 'digree', 'digree_duration',\n",
    "    # 'skill',\n",
    "    # 'company_emp_count', 'company_industry',\n",
    "columns = linkeddf.columns\n",
    "def custom_sort_key(org):\n",
    "    parts = org.split('_')\n",
    "    org_number = int(parts[1])\n",
    "    sub_number = int(parts[3]) if len(parts) > 3 else 0\n",
    "    return org_number, sub_number\n",
    "def custom_sort_key_comp(org):\n",
    "    parts = org.split('_')\n",
    "    org_number = int(parts[1])\n",
    "    return org_number\n",
    "\n",
    "sortlist = []\n",
    "\n",
    "# Sorting by 'name' and 'location'\n",
    "sortlist.extend(sorted([col for col in columns if 'name' in col]))\n",
    "sortlist.extend(sorted([col for col in columns if 'location' == col]))\n",
    "\n",
    "# Sorting by 'title', 'org', 'job_duration', and 'job_location'\n",
    "title_cols = sorted([col for col in columns if 'title' in col], key=custom_sort_key)\n",
    "org_cols = sorted([col for col in columns if 'org' in col], key=custom_sort_key)\n",
    "job_duration_cols = sorted([col for col in columns if 'job' in col and 'duration' in col], key=custom_sort_key)\n",
    "job_location_cols = sorted([col for col in columns if 'job' in col and 'location' in col], key=custom_sort_key)\n",
    "\n",
    "for title_col, org_col, job_duration_col, job_location_col in zip(title_cols, org_cols, job_duration_cols, job_location_cols):\n",
    "    sortlist.extend([org_col, title_col, job_duration_col, job_location_col])\n",
    "    \n",
    "institute_cols = sorted([col for col in columns if 'institute' in col], key=custom_sort_key)\n",
    "degree_cols = sorted([col for col in columns if 'digree' in col and 'duration' not in col], key=custom_sort_key)\n",
    "degree_duration_cols = sorted([col for col in columns if 'digree' in col and 'duration' in col], key=custom_sort_key)\n",
    "\n",
    "for institute_col, degree_col, degree_duration_col in zip(institute_cols, degree_cols, degree_duration_cols):\n",
    "    sortlist.extend([institute_col, degree_col, degree_duration_col])\n",
    "\n",
    "skill_cols = sorted([col for col in columns if 'skill' in col], key=custom_sort_key)\n",
    "sortlist.extend(skill_cols)\n",
    "\n",
    "company_emp_count_col = sorted([col for col in columns if 'company' in col and 'emp' in col], key=custom_sort_key_comp)\n",
    "company_industry_col = sorted([col for col in columns if 'company' in col and 'industry' in col], key=custom_sort_key_comp)\n",
    "\n",
    "for emp_count_col, industry_col in zip(company_emp_count_col, company_industry_col):\n",
    "    sortlist.extend([emp_count_col, industry_col])\n",
    "\n",
    "linkeddf = linkeddf.reindex(columns = sortlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkeddf.drop_duplicates(inplace = True)\n",
    "linkeddf = linkeddf.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5655, 527)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkeddf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_rows = 7278\n"
     ]
    }
   ],
   "source": [
    "print('total_rows =',1623 + linkeddf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkeddf.drop_duplicates(inplace=True)\n",
    "# linkeddf.to_csv('Linkedin_data.csv',index = False)\n",
    "australia_timezone = pytz.timezone('Australia/Sydney')\n",
    "current_time = datetime.datetime.now(australia_timezone)\n",
    "filename = 'Linkedin_Extract_'+ str(current_time.date()).replace('-', '')+'.xlsx'\n",
    "linkeddf.to_excel(filename,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://onedrive.live.com/?id=F87FC3AA6EB46E0%21197341&cid=0F87FC3AA6EB46E0'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://onedrive.live.com/?id=F87FC3AA6EB46E0%21197341&cid=0F87FC3AA6EB46E0'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
